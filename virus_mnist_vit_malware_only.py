# -*- coding: utf-8 -*-
"""Virus-MNIST-ViT-Malware-Only

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/137GSg2pSyOyFAxFtaSgBuskltjtLHRbJ
"""

!pip install vit_pytorch

from google.colab import drive

VIRUS_MNIST_DIRECTORY_RELATIVE_PATH = '5527_project/virusmnist'

drive.mount('/content/drive')
virusmnist_directory_absolute_path = f'/content/drive/MyDrive/{VIRUS_MNIST_DIRECTORY_RELATIVE_PATH}'

import torch

device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else "cpu"
print(f"Using {device} device")

import numpy as np
import pandas as pd


class MalwareOnlyVirusMnistCsvDataset(torch.utils.data.Dataset):
    def __init__(self, csv_filepath):
        # Read the CSV file at the given file path then limit the data to just
        # the labels and relevant features (ignore the hash at index 1026)
        raw_data = pd.read_csv(csv_filepath).to_numpy()[:, 0:1025] \
            .astype(np.float32)  # Ensure that all data has a consistent type so PyTorch can import it
        # Features are at indices 1-1025, labels at index 0
        features = torch.from_numpy(raw_data[:, 1:1025].reshape((len(raw_data), 1, 32, 32)))
        labels = torch.from_numpy(raw_data[:, 0]).long()

        malware_indices = labels != 0

        self.features = features[malware_indices]
        self.labels = labels[malware_indices].apply_(lambda element: element - 1)

    def __getitem__(self, idx):
        return self.features[idx], self.labels[idx]

    def __len__(self):
        return len(self.features)

training_dataset = MalwareOnlyVirusMnistCsvDataset(f'{virusmnist_directory_absolute_path}/train.csv')
testing_dataset = MalwareOnlyVirusMnistCsvDataset(f'{virusmnist_directory_absolute_path}/test.csv')

import sklearn

# Source for how to use weight parameter for CrossEntropyLoss: https://stackoverflow.com/a/67836741
numpy_training_labels = training_dataset.labels.numpy()
class_weights = sklearn.utils.class_weight.compute_class_weight('balanced', classes=np.unique(numpy_training_labels), y=numpy_training_labels)

training_data_loader = torch.utils.data.DataLoader(training_dataset, batch_size=5, shuffle=True, pin_memory=True)
testing_data_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=5, shuffle=True, pin_memory=True)

from enum import Enum
import torch.distributed as dist
import time

# PyTorch training code adapted from: https://github.com/pytorch/examples/blob/main/imagenet/main.py


class Summary(Enum):
    NONE = 0
    AVERAGE = 1
    SUM = 2
    COUNT = 3


class AverageMeter(object):
    """Computes and stores the average and current value"""
    def __init__(self, name, fmt=':f', summary_type=Summary.AVERAGE):
        self.name = name
        self.fmt = fmt
        self.summary_type = summary_type
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def all_reduce(self):
        if torch.cuda.is_available():
            device = torch.device("cuda")
        elif torch.backends.mps.is_available():
            device = torch.device("mps")
        else:
            device = torch.device("cpu")
        total = torch.tensor([self.sum, self.count], dtype=torch.float32, device=device)
        dist.all_reduce(total, dist.ReduceOp.SUM, async_op=False)
        self.sum, self.count = total.tolist()
        self.avg = self.sum / self.count

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
        return fmtstr.format(**self.__dict__)

    def summary(self):
        fmtstr = ''
        if self.summary_type is Summary.NONE:
            fmtstr = ''
        elif self.summary_type is Summary.AVERAGE:
            fmtstr = '{name} {avg:.3f}'
        elif self.summary_type is Summary.SUM:
            fmtstr = '{name} {sum:.3f}'
        elif self.summary_type is Summary.COUNT:
            fmtstr = '{name} {count:.3f}'
        else:
            raise ValueError('invalid summary type %r' % self.summary_type)

        return fmtstr.format(**self.__dict__)


class ProgressMeter(object):
    def __init__(self, num_batches, meters, prefix=""):
        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)
        self.meters = meters
        self.prefix = prefix

    def display(self, batch):
        entries = [self.prefix + self.batch_fmtstr.format(batch)]
        entries += [str(meter) for meter in self.meters]
        print('\t'.join(entries))

    def display_summary(self):
        entries = [" *"]
        entries += [meter.summary() for meter in self.meters]
        print(' '.join(entries))

    def _get_batch_fmtstr(self, num_batches):
        num_digits = len(str(num_batches // 1))
        fmt = '{:' + str(num_digits) + 'd}'
        return '[' + fmt + '/' + fmt.format(num_batches) + ']'


def accuracy(output, target, topk=(1,)):
    """Computes the accuracy over the k top predictions for the specified values of k"""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))

        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res


def train(train_loader, model, criterion, optimizer, epoch, device):
    batch_time = AverageMeter('Time', ':6.3f')
    data_time = AverageMeter('Data', ':6.3f')
    losses = AverageMeter('Loss', ':.4e')
    top1 = AverageMeter('Acc@1', ':6.2f')
    top5 = AverageMeter('Acc@5', ':6.2f')
    progress = ProgressMeter(
        len(train_loader),
        [batch_time, data_time, losses, top1, top5],
        prefix="Epoch: [{}]".format(epoch))

    # switch to train mode
    model.train()

    end = time.time()
    for i, (images, target) in enumerate(train_loader):
        images = images.to(device, non_blocking=True)
        target = target.to(device, non_blocking=True)

        # measure data loading time
        data_time.update(time.time() - end)

        # compute output
        output = model(images)
        loss = criterion(output, target)

        # measure accuracy and record loss
        acc1, acc5 = accuracy(output, target, topk=(1, 2))
        losses.update(loss.item(), images.size(0))
        top1.update(acc1[0], images.size(0))
        top5.update(acc5[0], images.size(0))

        # compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if i % int(len(train_loader) / 10) == 0:
            progress.display(i + 1)

def validate(val_loader, model, criterion):

    def run_validate(loader, base_progress=0):
        with torch.no_grad():
            end = time.time()
            for i, (images, target) in enumerate(loader):
                i = base_progress + i

                images = images.to(device, non_blocking=True)
                target = target.to(device, non_blocking=True)

                # compute output
                output = model(images)
                loss = criterion(output, target)

                # measure accuracy and record loss
                acc1, acc5 = accuracy(output, target, topk=(1, 2))
                losses.update(loss.item(), images.size(0))
                top1.update(acc1[0], images.size(0))
                top5.update(acc5[0], images.size(0))

                # measure elapsed time
                batch_time.update(time.time() - end)
                end = time.time()

                if i % int(len(loader) / 10) == 0:
                    progress.display(i + 1)

    batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
    losses = AverageMeter('Loss', ':.4e', Summary.NONE)
    top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
    top5 = AverageMeter('Acc@5', ':6.2f', Summary.AVERAGE)
    progress = ProgressMeter(
        len(val_loader), #+ (args.distributed and (len(val_loader.sampler) * args.world_size < len(val_loader.dataset))),
        [batch_time, losses, top1, top5],
        prefix='Test: ')

    # switch to evaluate mode
    model.eval()

    run_validate(val_loader)

    progress.display_summary()

    return top1.avg

criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, device=device, dtype=torch.float32), reduction='mean').to(device)

from vit_pytorch import SimpleViT

model = SimpleViT(
    image_size = 32,
    patch_size = 4,
    num_classes = 9,
    dim = 1024,
    depth = 6,
    heads = 16,
    mlp_dim = 2048,
    channels = 1,
)
model.to(device)

optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 5 epochs
learning_rate_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)

import os

EPOCH_COUNT = 10

best_model_params_path = 'best_model_params.pt'
best_acc1 = float('-inf')

for epoch in range(EPOCH_COUNT):
    train(training_data_loader, model, criterion, optimizer, epoch=epoch, device=device)

    # evaluate on validation set
    # FIXME: validate on VALIDATION SET not TESTING SET
    acc1 = validate(testing_data_loader, model, criterion)

    learning_rate_scheduler.step()

    # remember best acc@1 and save checkpoint
    is_best = acc1 > best_acc1
    best_acc1 = max(acc1, best_acc1)

    if is_best:
        torch.save(model.state_dict(), best_model_params_path)

print('best_acc1:', best_acc1)
# Re-load best model
model.load_state_dict(torch.load(best_model_params_path, weights_only=True))