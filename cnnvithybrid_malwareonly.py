# -*- coding: utf-8 -*-
"""CNNViTHybrid-MalwareOnly

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PAGG5typ1TG3cXglcogH4eE71ZUZcF_E
"""

MALWARE_ONLY: bool = True

CLASS_COUNT = 9 if MALWARE_ONLY else 10

"""NOTE: If file in shared with me, then select the 3 dots -> Organize -> Add Shortcut -> All locations -> My Drive"""

from google.colab import drive

VIRUS_MNIST_DIRECTORY_RELATIVE_PATH = '5527_project/virusmnist'

drive.mount('/content/drive')
virusmnist_directory_absolute_path = f'/content/drive/MyDrive/{VIRUS_MNIST_DIRECTORY_RELATIVE_PATH}'

import torch

device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else "cpu"
print(f"Using {device} device")

import numpy as np
import pandas as pd
from torchvision import transforms

transform_train = transforms.Compose([
    transforms.ToPILImage(),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

class VirusMnistCsvDataset(torch.utils.data.Dataset):
    def __init__(self, csv_filepath, indices=None, size=None, transform=None):
        # Load the full CSV file
        raw_data = pd.read_csv(csv_filepath).to_numpy()[:, 0:1025].astype(np.float32)

        # Features are at indices 1-1025, labels at index 0
        features = torch.from_numpy(raw_data[:, 1:1025].reshape((len(raw_data), 1, 32, 32)))  # Reshape for 32x32 images
        labels = torch.from_numpy(raw_data[:, 0]).long()

        # Keep only malware samples (labels != 0)
        if MALWARE_ONLY:
            malware_indices = labels != 0
            features = features[malware_indices]
            labels = labels[malware_indices].apply_(lambda x: x - 1)  # Reindex classes to start at 0

        # If 'size' is provided, use only a subset of the data
        if size:
            subset_size = int(len(features) * size)  # Use the given percentage (size is a float like 0.1 for 10%)
            features = features[:subset_size]
            labels = labels[:subset_size]

        # Use provided indices to create a subset of the data
        if indices is not None:
            features = features[indices]
            labels = labels[indices]

        transformed_features = []

        for feature in features:
            transformed_features.append(transform(feature.squeeze(0).numpy()) if transform else torch.tensor(feature))

        self.features = torch.stack(transformed_features).to(device)
        self.labels_cpu = labels
        self.labels = self.labels_cpu.to(device)

    def __getitem__(self, idx):
        img, label = self.features[idx], self.labels[idx]

        return img, label

    def __len__(self):
        return len(self.features)

"""If testing, you may stop executing here and resume at the testing checkpoint later"""

from sklearn.model_selection import train_test_split

# Split the training data into a training and validation set
labels = torch.from_numpy(pd.read_csv(f'{virusmnist_directory_absolute_path}/train.csv').to_numpy()[:, 0].astype(np.int64))

if MALWARE_ONLY:
    # Keep only malware samples (labels != 0)
    malware_indices = labels != 0
    labels = labels[malware_indices].apply_(lambda x: x - 1)  # Reindex classes to start at 0

# Stratified split to ensure the same label distribution in both training and validation sets
train_indices, val_indices = train_test_split(
    np.arange(len(labels)),
    test_size=0.1,  # 10% of training for validation
    stratify=labels,  # Ensure label distribution is uniform in both sets
    random_state=42  # Ensure reproducibility
)

train_dataset = VirusMnistCsvDataset(f'{virusmnist_directory_absolute_path}/train.csv', indices=train_indices, transform=transform_train)
val_dataset = VirusMnistCsvDataset(f'{virusmnist_directory_absolute_path}/train.csv', indices=val_indices, transform=transform_train)
testing_dataset = VirusMnistCsvDataset(f'{virusmnist_directory_absolute_path}/test.csv', transform=transform_train)

import sklearn

# Source for how to use weight parameter for CrossEntropyLoss: https://stackoverflow.com/a/67836741
numpy_training_labels = train_dataset.labels_cpu.numpy()
class_weights = sklearn.utils.class_weight.compute_class_weight('balanced', classes=np.unique(numpy_training_labels), y=numpy_training_labels)

training_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)
testing_data_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=32, shuffle=True)

from enum import Enum
import torch.distributed as dist
import time
import matplotlib.pyplot as plt
from tqdm import tqdm

# PyTorch training code adapted from: https://github.com/pytorch/examples/blob/main/imagenet/main.py


class Summary(Enum):
    NONE = 0
    AVERAGE = 1
    SUM = 2
    COUNT = 3


class AverageMeter(object):
    """Computes and stores the average and current value"""
    def __init__(self, name, fmt=':f', summary_type=Summary.AVERAGE):
        self.name = name
        self.fmt = fmt
        self.summary_type = summary_type
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count

    def all_reduce(self):
        if torch.cuda.is_available():
            device = torch.device("cuda")
        elif torch.backends.mps.is_available():
            device = torch.device("mps")
        else:
            device = torch.device("cpu")
        total = torch.tensor([self.sum, self.count], dtype=torch.float32, device=device)
        dist.all_reduce(total, dist.ReduceOp.SUM, async_op=False)
        self.sum, self.count = total.tolist()
        self.avg = self.sum / self.count

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
        return fmtstr.format(**self.__dict__)

    def summary(self):
        fmtstr = ''
        if self.summary_type is Summary.NONE:
            fmtstr = ''
        elif self.summary_type is Summary.AVERAGE:
            fmtstr = '{name} {avg:.3f}'
        elif self.summary_type is Summary.SUM:
            fmtstr = '{name} {sum:.3f}'
        elif self.summary_type is Summary.COUNT:
            fmtstr = '{name} {count:.3f}'
        else:
            raise ValueError('invalid summary type %r' % self.summary_type)

        return fmtstr.format(**self.__dict__)


class ProgressMeter(object):
    def __init__(self, num_batches, meters, mode, prefix=""):
        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)
        self.meters = meters
        self.prefix = prefix
        self.mode = mode

    def display(self, batch):
        entries = [self.prefix + self.batch_fmtstr.format(batch)]
        entries += [str(meter) for meter in self.meters]
        print('\t'.join(entries))

    def display_summary(self):
        entries = [str(self.mode) + ": "]
        entries += [meter.summary() for meter in self.meters]
        print(' '.join(entries))

    def _get_batch_fmtstr(self, num_batches):
        num_digits = len(str(num_batches // 1))
        fmt = '{:' + str(num_digits) + 'd}'
        return '[' + fmt + '/' + fmt.format(num_batches) + ']'


def accuracy(output, target, topk=(1,)):
    """Computes the accuracy over the k top predictions for the specified values of k"""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))

        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res


def train(train_loader, model, criterion, optimizer, epoch, device):
    batch_time = AverageMeter('Time', ':6.3f')
    data_time = AverageMeter('Data', ':6.3f')
    losses = AverageMeter('Loss', ':.4e')
    top1 = AverageMeter('Acc@1', ':6.2f')
    top5 = AverageMeter('Acc@2', ':6.2f')
    progress = ProgressMeter(
        len(train_loader),
        [batch_time, data_time, losses, top1, top5],
        "Train",
        prefix="Epoch: [{}]".format(epoch))

    # switch to train mode
    model.train()

    end = time.time()
    for i, (images, target) in tqdm(enumerate(train_loader), total=len(train_loader), desc="Training Epoch {}".format(epoch)):
        images = images.to(device, non_blocking=True)
        target = target.to(device, non_blocking=True)

        # measure data loading time
        data_time.update(time.time() - end)

        # compute output
        output = model(images)
        loss = criterion(output, target)

        # measure accuracy and record loss
        acc1, acc5 = accuracy(output, target, topk=(1, 2))
        losses.update(loss.item(), images.size(0))
        top1.update(acc1[0], images.size(0))
        top5.update(acc5[0], images.size(0))

        # compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

    progress.display_summary()
    return top1.avg, losses.avg

def validate(val_loader, model, criterion):

    def run_validate(loader, base_progress=0):
        with torch.no_grad():
            end = time.time()
            for i, (images, target) in enumerate(loader):
                i = base_progress + i

                images = images.to(device, non_blocking=True)
                target = target.to(device, non_blocking=True)

                # compute output
                output = model(images)
                loss = criterion(output, target)

                # measure accuracy and record loss
                acc1, acc5 = accuracy(output, target, topk=(1, 2))
                losses.update(loss.item(), images.size(0))
                top1.update(acc1[0], images.size(0))
                top5.update(acc5[0], images.size(0))

                # measure elapsed time
                batch_time.update(time.time() - end)
                end = time.time()

    batch_time = AverageMeter('Time', ':6.3f', Summary.NONE)
    losses = AverageMeter('Loss', ':.4e', Summary.NONE)
    top1 = AverageMeter('Acc@1', ':6.2f', Summary.AVERAGE)
    top5 = AverageMeter('Acc@2', ':6.2f', Summary.AVERAGE)
    progress = ProgressMeter(
        len(val_loader), #+ (args.distributed and (len(val_loader.sampler) * args.world_size < len(val_loader.dataset))),
        [batch_time, losses, top1, top5],
        "Validation",
        prefix='Test: ')

    # switch to evaluate mode
    model.eval()

    run_validate(val_loader)

    progress.display_summary()
    return top1.avg

import torch
import torch.nn as nn
import math

class HybridCNNViT(nn.Module):
    def __init__(self, num_classes, cnn_out_channels=64, transformer_dim=128, num_heads=8, num_layers=6, mlp_dim=256):
        super().__init__()
        # CNN backbone
        self.cnn = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 32x32 -> 16x16
            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 16x16 -> 8x8
            nn.Conv2d(128, cnn_out_channels, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(cnn_out_channels),
            nn.ReLU(),
        )
        self.feature_size = 8
        # Project CNN features to Transformer dimension
        self.projection = nn.Linear(cnn_out_channels, transformer_dim)
        # Positional embeddings
        self.positional_embedding = nn.Parameter(torch.randn((self.feature_size**2, transformer_dim)))
        # Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=transformer_dim,
            nhead=num_heads,
            dim_feedforward=mlp_dim,
            activation='gelu',
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        # Classifier
        self.classifier = nn.Linear(transformer_dim, num_classes)

    def forward(self, x):
        # CNN forward
        cnn_out = self.cnn(x)  # (B, C, 8, 8)
        B, C, H, W = cnn_out.size()
        # Reshape to (B, H*W, C)
        cnn_out = cnn_out.permute(0, 2, 3, 1).reshape(B, H*W, C)
        # Project to transformer dimension
        projected = self.projection(cnn_out)
        # Add positional embeddings
        projected += self.positional_embedding.unsqueeze(0)
        # Transformer encoder
        transformer_out = self.transformer_encoder(projected)
        # Average tokens and classify
        avg_pool = transformer_out.mean(dim=1)
        logits = self.classifier(avg_pool)
        return logits

criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, device=device, dtype=torch.float32), reduction='mean').to(device)

model = HybridCNNViT(num_classes=CLASS_COUNT).to(device)

optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=1e-4,
    weight_decay=1e-4
)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)

import os
import matplotlib.pyplot as plt
from tqdm import tqdm

train_losses = []
train_accuracies = []
val_accuracies = []

EPOCH_COUNT = 30
best_model_params_path = 'best-model-params-' + ('malware-only' if MALWARE_ONLY else '10-class') + '.pt'
best_acc1 = float('-inf')

for epoch in range(EPOCH_COUNT):
    print(f"Epoch {epoch+1}/{EPOCH_COUNT}")

    # Train for one epoch
    train_acc, train_loss = train(training_data_loader, model, criterion, optimizer, epoch, device)
    train_losses.append(train_loss)
    train_accuracies.append(train_acc)

    # Validate after each epoch
    val_acc = validate(validation_data_loader, model, criterion)
    val_accuracies.append(val_acc)

    # Adjust learning rate scheduler
    scheduler.step()

    # Save model if it's the best so far
    is_best = val_acc > best_acc1
    best_acc1 = max(val_acc, best_acc1)
    if is_best:
        torch.save(model.state_dict(), best_model_params_path)

# Re-load best model
model.load_state_dict(torch.load(best_model_params_path, weights_only=True))
print(f'Best validation accuracy: {best_acc1}')

import matplotlib.pyplot as plt

train_losses_plot = [x.item() if torch.is_tensor(x) else x for x in train_losses]
train_accuracies_plot = [x.item() if torch.is_tensor(x) else x for x in train_accuracies]
val_accuracies_plot = [x.item() if torch.is_tensor(x) else x for x in val_accuracies]

plt.figure(figsize=(10, 5))

# Training Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, EPOCH_COUNT + 1), train_losses_plot, label="Train Loss", color='orange')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(range(1, EPOCH_COUNT + 1), train_accuracies_plot, label="Train Accuracy", color='blue')
plt.plot(range(1, EPOCH_COUNT + 1), val_accuracies_plot, label="Validation Accuracy", color='green')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend(loc='best')
plt.grid(True)

plt.tight_layout()
plt.show()

"""Testing checkpoint"""

if not model:
    model = HybridCNNViT(num_classes=CLASS_COUNT).to(device)

    model.load_state_dict(torch.load(best_model_params_path, weights_only=True))

    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, device=device, dtype=torch.float32), reduction='mean').to(device)

    testing_data_loader = torch.utils.data.DataLoader(testing_dataset, batch_size=32, shuffle=True)

from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from itertools import cycle


def test(test_loader, model, criterion, device):
    all_preds = []
    all_probs = []
    all_targets = []

    def run_test(loader):
        with torch.no_grad():
            end = time.time()
            for i, (images, target) in enumerate(loader):
                images = images.to(device, non_blocking=True)
                target = target.to(device, non_blocking=True)

                output = model(images)
                loss = criterion(output, target)

                acc1, acc5 = accuracy(output, target, topk=(1, 2))
                losses.update(loss.item(), images.size(0))
                top1.update(acc1[0], images.size(0))
                top5.update(acc5[0], images.size(0))

                probs = torch.softmax(output, dim=1)
                preds = torch.argmax(probs, dim=1)

                all_preds.extend(preds.cpu().numpy())
                all_probs.extend(probs.cpu().numpy())  # Full class probabilities
                all_targets.extend(target.cpu().numpy())

                batch_time.update(time.time() - end)
                end = time.time()

    batch_time = AverageMeter('Time', ':6.3f')
    losses = AverageMeter('Loss', ':.4e')
    top1 = AverageMeter('Acc@1', ':6.2f')
    top5 = AverageMeter('Acc@5', ':6.2f')

    model.eval()
    run_test(test_loader)

    return top1.avg, all_preds, all_probs, all_targets


final_test_acc, all_preds, all_probs, all_targets = test(testing_data_loader, model, criterion, device)
print(f'Final test accuracy: {final_test_acc:.2f}%')

precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_preds, average='weighted')
print(f'Precision: {precision:.2f}')
print(f'Recall:    {recall:.2f}')
print(f'F1 Score:  {f1:.2f}')

print("\nClassification Report:")
print(classification_report(all_targets, all_preds))

cm = confusion_matrix(all_targets, all_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues', xticks_rotation=45)
plt.title("Confusion Matrix")
plt.show()

# Multiclass ROC curve & AUC
y_true_bin = label_binarize(all_targets, classes=list(range(CLASS_COUNT)))
all_probs = np.array(all_probs).reshape(-1, CLASS_COUNT)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(CLASS_COUNT):
    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], all_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

fpr["micro"], tpr["micro"], _ = roc_curve(y_true_bin.ravel(), all_probs.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# Plot all ROC curves
plt.figure()
colors = cycle([
    'aqua', 'darkorange', 'cornflowerblue', 'red', 'green',
    'purple', 'brown', 'pink', 'gray'
])
for i, color in zip(range(CLASS_COUNT), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
              label=f'Class {i} (area = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multiclass ROC Curve')
plt.legend(loc='lower right')
plt.show()